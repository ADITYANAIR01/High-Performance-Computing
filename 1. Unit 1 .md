    Introduction to Parallel and Distributed Computing

Parallel computing is  the concurrent use of multiple computer resources to solve a computational problem

High performance computing is the use of high-speed processors, clusters, and networks to perform complex calculations and data analysis.

Data parallelism is the execution of the same task on different data sets by multiple processing cores.

Flynn's taxonomy is a classification of computer architectures based on the number and type of instruction and data streams.

Array processor is a processor that performs operations on large arrays of data using a single instruction stream and multiple data streams (SIMD).

Multiprocessor is a system with two or more CPUs that share a common memory and can execute multiple tasks concurrently (MIMD).

Multicomputer is a system with multiple processors that have their own private memory and communicate via a network (MIMD).

Message passing interface (MPI) is a standard for inter-process communication in parallel and distributed computing.


    Advantages and Disadvatages of Parallel computing

* * Advantages 

* Because multiple resources work together to reduce time and expenses, it saves time and money. 

* You can use a lot of computing resources at once to do several tasks. For modeling, simulating, and interpreting complex real-world events.

 
* * Disadvantages

* Power usage for multi-core designs is high. Due to the complexity of communication and coordination,parallel solutions are more challenging to implement,
debug, and prove correct, and they frequently perform worse than their serial counterparts